{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training CNN\n",
    "\n",
    "##### Step-1 → Convolution\n",
    "##### Step-2 → Max Pooling\n",
    "##### Step-3 → Flattening\n",
    "##### Step-4 → Full Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step-1 → Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step-2 → Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another layer to improve effeciency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# No need for input_shape as it works on pooled data added at first layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step-3 → Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step-4 → Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 128, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))  #Sigmoid for binary outcome, softmasx for non binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# binary_crossentrpoy : as we have binary outcome\n",
    "# categorical_crossentropy : for non binary outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Fitting the CNN to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 1821s 228ms/step - loss: 0.3806 - accuracy: 0.8208 - val_loss: 0.2630 - val_accuracy: 0.8117\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 2004s 251ms/step - loss: 0.1347 - accuracy: 0.9474 - val_loss: 1.7631 - val_accuracy: 0.8053\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 3458s 432ms/step - loss: 0.0626 - accuracy: 0.9771 - val_loss: 0.7611 - val_accuracy: 0.8013\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 2262s 283ms/step - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.8278 - val_accuracy: 0.7919\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 2385s 298ms/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 1.5464 - val_accuracy: 0.7967\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 2216s 277ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 1.6945 - val_accuracy: 0.7918\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 2140s 267ms/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.7804 - val_accuracy: 0.8087\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 1847s 231ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 2.3798 - val_accuracy: 0.8132\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 1754s 219ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.9138 - val_accuracy: 0.8049\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 1747s 218ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 4.1925 - val_accuracy: 0.8166\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 1752s 219ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.5634 - val_accuracy: 0.7932\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 1748s 218ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 1.2870 - val_accuracy: 0.8001\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 1752s 219ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.8258 - val_accuracy: 0.7935\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 1751s 219ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 2.8601 - val_accuracy: 0.8050\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 1756s 220ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 1.3381 - val_accuracy: 0.8019\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 1934s 242ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 2.7509 - val_accuracy: 0.8061\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 1919s 240ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 3.4520 - val_accuracy: 0.8047\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 1924s 241ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.7735 - val_accuracy: 0.8142\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 1928s 241ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 3.1720 - val_accuracy: 0.8112\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 1787s 223ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 2.5863 - val_accuracy: 0.8097\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 1738s 217ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 1.8994 - val_accuracy: 0.8179\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 1738s 217ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 1.0857 - val_accuracy: 0.8160\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 1742s 218ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 3.0210 - val_accuracy: 0.8016\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 1743s 218ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 1.4177 - val_accuracy: 0.8141\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 1748s 218ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 5.2242 - val_accuracy: 0.8065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ddf13b86a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch=8000,\n",
    "                         epochs=25,\n",
    "                         validation_data=test_set,\n",
    "                         validation_steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : Making new Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'Dogs'\n",
    "else:\n",
    "    prediction = 'Cats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image belongs to category of  Dogs\n"
     ]
    }
   ],
   "source": [
    "print(\"Image belongs to category of \", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
